{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMU6/c8HFBxo6kF7VAeB3Qa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/djdunc/hercules/blob/main/data_processing/locations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Takes patient journey data and adds in machine location information based on a set of rectangles describing where machines are located."
      ],
      "metadata": {
        "id": "z9PdON4210cN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7yNB2vvuGCXo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def filter_patient_data(csv_file, patient_id):\n",
        "    \"\"\"\n",
        "    Loads a CSV file into a pandas DataFrame and filters it by patient ID.\n",
        "\n",
        "    Args:\n",
        "        csv_file (str): Path to the CSV file.\n",
        "        patient_id (str): The patient ID to filter by.\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: A DataFrame containing only the data for the specified\n",
        "                         patient ID, or an empty DataFrame if the file doesn't exist\n",
        "                         or the patient ID is not found. Returns an error message if the file is not a valid CSV.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(csv_file)\n",
        "    except FileNotFoundError:\n",
        "        return \"Error: File not found.\"\n",
        "    except pd.errors.ParserError:\n",
        "        return \"Error: Invalid CSV file format.\"\n",
        "    except Exception as e: # Catch other potential pandas exceptions\n",
        "        return f\"An error occurred while reading the file: {e}\"\n",
        "\n",
        "\n",
        "    if 'Patient' not in df.columns:\n",
        "        return \"Error: 'Patient' column not found in CSV.\"\n",
        "\n",
        "    filtered_df = df[df['Patient'] == patient_id]\n",
        "    return filtered_df\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def is_location_within_rectangle(x, y, rect):\n",
        "    \"\"\"Checks if (x, y) is within a given rectangle.\n",
        "\n",
        "    Args:\n",
        "        x: x-coordinate.\n",
        "        y: y-coordinate.\n",
        "        rect: A tuple or list defining the rectangle (x1, y1, x2, y2).\n",
        "\n",
        "    Returns:\n",
        "        bool: True if within, False otherwise.\n",
        "    \"\"\"\n",
        "    x1, y1, x2, y2 = rect\n",
        "    return x1 <= x <= x2 and y2 <= y <= y1  # Corrected y-coordinate comparison\n"
      ],
      "metadata": {
        "id": "FZOQGYXQLRnR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rectangles = {\n",
        "    \"Reception\": (0, 14.9, 8.38, 6.31),\n",
        "    \"WC\": (24.95, 3.33, 27.67, 1.66),\n",
        "    \"MR 1\": (25.95, 12.77,28.24, 9.30),\n",
        "    \"MR 2\": (23.51, 12.77,25.80, 9.30),\n",
        "    \"MR 3\": (17.28, 15.93,20.95, 13.63),\n",
        "    \"MR 4\": (13.46, 15.96,17.13, 13.63),\n",
        "    \"AF LHS\": (2.67, 6.08,4.76, 3.87),\n",
        "    \"AF RHS\": (4.94, 6.06,7.03, 3.87),\n",
        "    \"HFA 1\": (0.00, 3.96,2.30, 2.55),\n",
        "    \"HFA 2\": (0.14, 2.32,1.66, 0.14),\n",
        "    \"HFA 3\": (2.38, 2.41,3.87, 0.17),\n",
        "    \"HFA 4\": (4.10, 2.41,5.60, 0.14),\n",
        "    \"HFA 5\": (5.85, 2.41,7.32, 0.14),\n",
        "    \"HFA 6\": (7.61, 2.41,9.10, 0.17),\n",
        "    \"Vision 1\": (23.76, 7.43,25.57, 3.67),\n",
        "    \"Vision 2\": (25.74, 7.40,27.52, 3.76),\n",
        "    \"Vision 3\": (30.28, 7.38,34.01, 5.63),\n",
        "    \"Vision 4\": (30.28, 9.24,34.01, 7.58),\n",
        "    \"Vision 5\": (30.28, 11.08,34.04, 9.44),\n",
        "    \"Vision 6\": (30.25, 13.00,34.01, 11.31),\n",
        "    \"Vision 7\": (30.28, 14.92,34.01, 13.14),\n",
        "    \"MR Dilation 1\": (29.79, 16.02,30.94, 15.04),\n",
        "    \"MR Dilation 2\": (31.51, 16.02,32.63, 15.07),\n",
        "    \"MR Dilation 3\": (33.09, 15.99,34.15, 15.10),\n",
        "    \"MR Dilation 4\": (33.01, 17.77,34.10, 16.68),\n",
        "    \"MR Dilation 5\": (31.05, 17.77,32.14, 16.68),\n",
        "    \"MR Dilation 6\": (29.19, 17.77,30.28, 16.62),\n",
        "    \"MR Dilation 7\": (27.52, 17.71,28.59, 16.68),\n",
        "    \"Research 1\": (8.73, 5.74,12.43, 3.82),\n",
        "    \"Research 2\": (8.67, 8.44,12.28, 6.63),\n",
        "    \"Research 3\": (8.67, 10.45,12.31, 8.64),\n",
        "    \"Research 4\": (8.67, 12.46,12.34, 10.62),\n",
        "    \"Research 5\": (8.64, 14.49,12.34, 12.63),\n",
        "    \"Research 6\": (12.74, 18.20,16.50, 16.36),\n",
        "    \"Glaucoma 1 ORA\": (17.88, 6.40,21.58, 3.93),\n",
        "    \"Glaucoma 1 OCT\": (15.64, 6.40,17.77, 3.93),\n",
        "    \"Glaucoma 1 WF\": (13.60, 6.37,15.50, 3.93),\n",
        "    \"Glaucoma 2 ORA\": (17.88, 9.04,21.61, 6.57),\n",
        "    \"Glaucoma 2 OCT\": (15.64, 9.01,17.77, 6.57),\n",
        "    \"Glaucoma 2 WF\": (13.63, 9.07,15.53, 6.60),\n",
        "    \"Glaucoma 3 ORA\": (17.91, 11.62,21.61, 9.21),\n",
        "    \"Glaucoma 3 OCT\": (15.70, 11.65,17.79, 9.24),\n",
        "    \"Glaucoma 3 WF\": (13.63, 11.65,15.53, 9.21)\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1Y-mviJxGIsw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_tasks(task_list_csv, rectangles, output_csv_path=\"combined_output.csv\"):\n",
        "    \"\"\"\n",
        "    Processes tasks from a task list CSV, appends results, and sorts by 'starttime'.\n",
        "\n",
        "    Args:\n",
        "        task_list_csv (str): Path to the CSV containing task information.\n",
        "        rectangles: A dictionary where keys are rectangle names (strings) and\n",
        "                    values are tuples/lists defining the rectangles (x1, y1, x2, y2).\n",
        "        output_csv_path (str): The path to the output CSV file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        tasks_df = pd.read_csv(task_list_csv)\n",
        "        #print(\"CSV Column Names:\", tasks_df.columns.tolist())\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Task list CSV not found at {task_list_csv}\")\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading task list CSV: {e}\")\n",
        "        return\n",
        "\n",
        "    print(tasks_df)\n",
        "\n",
        "    all_data = pd.DataFrame()  # Initialize an empty DataFrame\n",
        "\n",
        "    for index, row in tasks_df.iterrows():\n",
        "        file_path = row['csv_file_path']\n",
        "        patient_id = row['patient_id_to_filter']\n",
        "        unique_patient_id = row['Unique_Patient_ID'] # this is the one used by Rosica\n",
        "\n",
        "        filtered_data = filter_patient_data(file_path, patient_id)\n",
        "\n",
        "        if isinstance(filtered_data, pd.DataFrame):\n",
        "            if not filtered_data.empty:\n",
        "                try:\n",
        "                    filtered_data[['xlocation', 'ylocation']] = filtered_data['Location'].apply(lambda loc: tuple(map(float, loc.replace('\"', '').split(',')))).tolist()\n",
        "                    filtered_data['starttime'] = pd.to_datetime(filtered_data['starttime'])\n",
        "\n",
        "                except (ValueError, AttributeError):\n",
        "                    print(f\"Error processing {file_path}: Could not convert xlocation or ylocation to floats. Check data format.\")\n",
        "                    continue\n",
        "\n",
        "                filtered_data['within_rectangle'] = \"\"\n",
        "\n",
        "                for rect_name, rect_coords in rectangles.items():\n",
        "                    filtered_data.loc[filtered_data.apply(lambda row: is_location_within_rectangle(row['xlocation'], row['ylocation'], rect_coords), axis=1), 'within_rectangle'] += rect_name + \",\"\n",
        "\n",
        "                filtered_data['within_rectangle'] = filtered_data['within_rectangle'].str.rstrip(',')\n",
        "                filtered_data['Unique_Patient_ID'] = unique_patient_id # Add Unique_Patient_ID\n",
        "\n",
        "\n",
        "                all_data = pd.concat([all_data, filtered_data], ignore_index=True)\n",
        "\n",
        "            else:\n",
        "                print(f\"No data found for Patient ID: {patient_id} in file: {file_path}\")\n",
        "        elif isinstance(filtered_data, str):\n",
        "            print(f\"Error processing {file_path}: {filtered_data}\")\n",
        "        else:\n",
        "            print(f\"An unexpected error occurred while processing {file_path}\")\n",
        "\n",
        "    if not all_data.empty:\n",
        "        all_data = all_data.sort_values(by='starttime')\n",
        "        all_data.to_csv(output_csv_path, index=False)\n",
        "        print(f\"Combined data saved to {output_csv_path}\")\n",
        "    else:\n",
        "        print(\"No data was processed.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WUpSwf6lmxj-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "task_list_csv = \"ethno_patients.csv\"\n",
        "process_tasks(task_list_csv, rectangles, \"combined_data.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "YHHFfU0GhBcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extra"
      ],
      "metadata": {
        "id": "wFRsr0rm1kKn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "process_data was used when processing single files"
      ],
      "metadata": {
        "id": "mQNJyT_N1YKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_data(csv_file_path, patient_id_to_filter, rectangles, output_csv_path):\n",
        "    \"\"\"Processes data, checking against multiple rectangles.\n",
        "\n",
        "    Args:\n",
        "        csv_file_path: Path to CSV.\n",
        "        patient_id_to_filter: Patient ID.\n",
        "        rectangles: A dictionary where keys are rectangle names (strings) and\n",
        "                    values are tuples/lists defining the rectangles (x1, y1, x2, y2).\n",
        "        output_file_path: Path to output text file.\n",
        "    \"\"\"\n",
        "\n",
        "    filtered_data = filter_patient_data(csv_file_path, patient_id_to_filter)\n",
        "\n",
        "    if isinstance(filtered_data, pd.DataFrame):\n",
        "        if not filtered_data.empty:\n",
        "            try:\n",
        "                filtered_data[['xlocation', 'ylocation']] = filtered_data['Location'].apply(lambda loc: tuple(map(float, loc.replace('\"', '').split(',')))).tolist()\n",
        "                #Convert starttime to datetime\n",
        "                filtered_data['starttime'] = pd.to_datetime(filtered_data['starttime'])\n",
        "\n",
        "            except (ValueError, AttributeError):\n",
        "                return \"Error: Could not convert xlocation or ylocation to floats. Check data format.\"\n",
        "\n",
        "            filtered_data['within_rectangle'] = \"\"  # Initialize the column\n",
        "\n",
        "            for rect_name, rect_coords in rectangles.items():\n",
        "                filtered_data.loc[filtered_data.apply(lambda row: is_location_within_rectangle(row['xlocation'], row['ylocation'], rect_coords), axis=1), 'within_rectangle'] += rect_name + \",\" # Append the rectangle name, comma separated.\n",
        "\n",
        "            #Remove the trailing comma\n",
        "            filtered_data['within_rectangle'] = filtered_data['within_rectangle'].str.rstrip(',')\n",
        "\n",
        "            # Sort by starttime\n",
        "            filtered_data = filtered_data.sort_values(by='starttime')\n",
        "            print(filtered_data.to_string())\n",
        "            # Save to CSV\n",
        "            filtered_data.to_csv(output_csv_path, index=False)  # index=False prevents writing the index column\n",
        "\n",
        "\n",
        "\n",
        "        else:\n",
        "            print(f\"No data found for Patient ID: {patient_id_to_filter}\")\n",
        "    elif isinstance(filtered_data, str):\n",
        "        print(filtered_data)\n",
        "    else:\n",
        "        print(\"An unexpected error occurred.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Re79_dq5LcYG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extra bit of code to loop through all the data to see which records are not in any of the input files - takes a few mins to run"
      ],
      "metadata": {
        "id": "Rnhz0bVD1CpH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def check_patient_id_files(task_list_csv, input_files, output_file=\"patient_id_file_mapping.txt\"):\n",
        "    \"\"\"\n",
        "    Checks if patient IDs from a task list CSV are present in specified input CSV files.\n",
        "\n",
        "    Args:\n",
        "        task_list_csv (str): Path to the task list CSV.\n",
        "        input_files (list): List of paths to the input CSV files.\n",
        "        output_file (str): Path to the output text file.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        tasks_df = pd.read_csv(task_list_csv)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Task list CSV not found at {task_list_csv}\")\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading task list CSV: {e}\")\n",
        "        return\n",
        "\n",
        "    results = [] # list to store results\n",
        "\n",
        "    for index, row in tasks_df.iterrows():\n",
        "        patient_id = row['patient_id_to_filter']\n",
        "        found_in_files = []\n",
        "\n",
        "        for input_file in input_files:\n",
        "            try:\n",
        "                df = pd.read_csv(input_file)\n",
        "                if patient_id in df['Patient'].values: # Check if patient_id is present\n",
        "                    found_in_files.append(os.path.basename(input_file)) # Append file name to the list\n",
        "            except FileNotFoundError:\n",
        "                print(f\"Warning: Input file not found: {input_file}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Error reading input file {input_file}: {e}\")\n",
        "\n",
        "        if found_in_files:\n",
        "            results.append(f\"Patient ID: {patient_id} found in: {', '.join(found_in_files)}\")\n",
        "        else:\n",
        "            results.append(f\"Patient ID: {patient_id} not found in any specified files.\")\n",
        "\n",
        "    # Write results to output file\n",
        "    with open(output_file, \"w\") as f:\n",
        "        for result in results:\n",
        "            f.write(result + \"\\n\")\n",
        "\n",
        "    print(f\"Patient ID to file mapping written to {output_file}\")\n",
        "\n",
        "# Example Usage:\n",
        "task_list_csv = \"ethno_patients.csv\"  # Replace with your task list CSV path\n",
        "input_files = [\"P1_input.csv\", \"P2_input.csv\", \"P3_input.csv\", \"P4_input.csv\"] # list of input files\n",
        "\n",
        "check_patient_id_files(task_list_csv, input_files, \"patient_file_mapping.txt\") # specify output file"
      ],
      "metadata": {
        "id": "GO1WFqfEwVmJ",
        "outputId": "7adb7ede-646a-45f5-db16-54ff14f59b0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient ID to file mapping written to patient_file_mapping.txt\n"
          ]
        }
      ]
    }
  ]
}